{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e0bb14a",
   "metadata": {},
   "source": [
    "## PDF to .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c4696e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved Baymax_KnowledgeBase/2022, CURRENT Medical Diagnosis and Treatment- Original Revised.txt\n",
      "✅ Saved Baymax_KnowledgeBase/Symptoms to diagnosis Revised.txt\n",
      "✅ Saved Baymax_KnowledgeBase/Where there is no Doctor - David Werner Revised.1.txt\n",
      "✅ Saved Baymax_KnowledgeBase/National-Formulary-of-India-2011 Revised.txt\n",
      "✅ Saved Baymax_KnowledgeBase/03_PHC_IPHS_Guidelines-2022 Revised.txt\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "# Input and output folders\n",
    "pdf_folder = \"pdfs\"\n",
    "output_folder = \"Baymax_KnowledgeBase\"\n",
    "\n",
    "# Make sure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through each PDF\n",
    "for filename in os.listdir(pdf_folder):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_folder, filename)\n",
    "        doc = fitz.open(pdf_path)\n",
    "\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "\n",
    "        # Remove .pdf and save as .txt\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        txt_path = os.path.join(output_folder, f\"{base_name}.txt\")\n",
    "\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "        print(f\"✅ Saved {txt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97752d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Renamed: 2022, CURRENT Medical Diagnosis and Treatment- Original Revised.txt → cmdt.txt\n",
      "✅ Renamed: Symptoms to diagnosis Revised.txt → symptom_flow.txt\n",
      "✅ Renamed: Where there is no Doctor - David Werner Revised.1.txt → rural_care.txt\n",
      "✅ Renamed: National-Formulary-of-India-2011 Revised.txt → nfi.txt\n",
      "✅ Renamed: 03_PHC_IPHS_Guidelines-2022 Revised.txt → iphs.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "rename_map = {\n",
    "    \"2022, CURRENT Medical Diagnosis and Treatment- Original Revised.txt\": \"cmdt.txt\",\n",
    "    \"Symptoms to diagnosis Revised.txt\": \"symptom_flow.txt\",\n",
    "    \"Where there is no Doctor - David Werner Revised.1.txt\": \"rural_care.txt\",\n",
    "    \"National-Formulary-of-India-2011 Revised.txt\": \"nfi.txt\",\n",
    "    \"03_PHC_IPHS_Guidelines-2022 Revised.txt\": \"iphs.txt\",\n",
    "}\n",
    "\n",
    "base_path = \"Baymax_KnowledgeBase\"\n",
    "\n",
    "for old_name, new_name in rename_map.items():\n",
    "    old_path = os.path.join(base_path, old_name)\n",
    "    new_path = os.path.join(base_path, new_name)\n",
    "    if os.path.exists(old_path):\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\"✅ Renamed: {old_name} → {new_name}\")\n",
    "    else:\n",
    "        print(f\"❌ File not found: {old_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb795ad1",
   "metadata": {},
   "source": [
    "## Smart Chunking & Metadata Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00ebc209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/devayushrout/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef4c9677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tiktoken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "457f7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"p50k_base\")\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17f59d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_chunk(text, source, max_tokens=500):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_tokens = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = count_tokens(sentence)\n",
    "        if current_tokens + tokens > max_tokens:\n",
    "            if current_chunk:\n",
    "                chunks.append({\n",
    "                    \"text\": current_chunk.strip(),\n",
    "                    \"metadata\": {\n",
    "                        \"source\": source\n",
    "                    }\n",
    "                })\n",
    "            current_chunk = sentence\n",
    "            current_tokens = tokens\n",
    "        else:\n",
    "            current_chunk += \" \" + sentence\n",
    "            current_tokens += tokens\n",
    "\n",
    "    # Add last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append({\n",
    "            \"text\": current_chunk.strip(),\n",
    "            \"metadata\": {\n",
    "                \"source\": source\n",
    "            }\n",
    "        })\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5cf4e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 7435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "knowledge_dir = \"Baymax_KnowledgeBase\"\n",
    "all_chunks = []\n",
    "\n",
    "for filename in tqdm(os.listdir(knowledge_dir)):\n",
    "    filepath = os.path.join(knowledge_dir, filename)\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw_text = f.read()\n",
    "\n",
    "    source_name = filename.replace(\".txt\", \"\")\n",
    "    chunks = smart_chunk(raw_text, source=source_name)\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "print(f\"Total chunks created: {len(all_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0da43249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Section\\nObjectives of IPHS for HWC-PHC | 5 \\nObjectives of IPHS \\nfor HWC-PHC\\n3\\nThe broad objectives of the Indian Public Health Standards (IPHS) for PHC in rural and urban areas include \\nthe following:\\n1. To define uniform benchmark to ensure high quality services that are accountable, responsive, and \\nsensitive to the needs of the community. 2. To specify the minimum assured (essential) and achievable (desirable) services that are expected to \\nbe provided at different levels of public health facilities. 3. To provide guidance on health systems strengthening components which includes architectural \\ndesign of facilities, human resources for health, drugs, diagnostics, equipment, administrative and \\nlogistical support services to improve the overall health related outcomes \\n4. To achieve and maintain an acceptable standard of the quality of care at public facilities\\n5. To facilitate monitoring and supervision of the facilities\\n6. To provide guidance and tools for governance, leadership and evaluation. Section\\nPopulation Norms for HWC-PHC | 7 \\nPopulation Norms \\nfor HWC-PHC\\n5\\nNormally, a PHC in rural areas is to be established for a population of 20,000 (in hilly and tribal areas) and \\n30,000 (in plains). It should be established co-terminus with Panchayats (depending upon the population) to \\nestablish effective convergence and linkages with citizen centric services. A Primary Health Centre (PHC) that \\nis linked to a cluster of Sub Health Centre - HWCs would be strengthened as HWC to deliver the expanded \\nrange of primary care services with complete 12 package of services. In addition, it would also serve as the \\nfirst point of referral for all the SHC-HWCs in its jurisdiction. In urban areas, usually the population density is high and there are various types of health care facilities \\nwhich provide inpatient care. So, the approach in urban areas for establishing PHCs shall be different from \\nthat in rural areas. UPHCs are established for every 50,000 population, and in close proximity to urban \\nslums.', 'metadata': {'source': 'iphs'}}\n"
     ]
    }
   ],
   "source": [
    "print(all_chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "046e1e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"baymax_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_chunks, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa37c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "import os\n",
    "\n",
    "docs = []\n",
    "\n",
    "base_path = \"Baymax_KnowledgeBase\"\n",
    "\n",
    "# Manual source labels for each file\n",
    "file_to_source = {\n",
    "    \"rural_care.txt\": \"rural_care\",\n",
    "    \"cmdt.txt\": \"clinical_guidelines\",\n",
    "    \"symptom_flow.txt\": \"consultation_flow\",\n",
    "    \"iphs.txt\": \"protocol_guidelines\",\n",
    "    \"nfi.txt\": \"medication_safety\"\n",
    "}\n",
    "\n",
    "# Optional: Priority settings (used later for filtering)\n",
    "file_priority = {\n",
    "    \"rural_care.txt\": 1,\n",
    "    \"symptom_flow.txt\": 2,\n",
    "    \"iphs.txt\": 2,\n",
    "    \"cmdt.txt\": 3,\n",
    "    \"nfi.txt\": 3\n",
    "}\n",
    "\n",
    "# Loop and load\n",
    "for filename in os.listdir(base_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        filepath = os.path.join(base_path, filename)\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "            docs.append(Document(\n",
    "                page_content=content,\n",
    "                metadata={\n",
    "                    \"source\": file_to_source.get(filename, \"unknown\"),\n",
    "                    \"priority\": file_priority.get(filename, 3),\n",
    "                    \"filename\": filename\n",
    "                }\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf326ff",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22572185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 7435 chunks into LangChain Document format.\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "import json\n",
    "\n",
    "with open(\"baymax_chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    loaded_chunks = json.load(f)\n",
    "\n",
    "document_chunks = [\n",
    "    Document(page_content=chunk[\"text\"], metadata=chunk[\"metadata\"])\n",
    "    for chunk in loaded_chunks\n",
    "]\n",
    "\n",
    "print(f\"✅ Loaded {len(document_chunks)} chunks into LangChain Document format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7ea4078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f993df",
   "metadata": {},
   "source": [
    "## VECTOR STORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70d309ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vectorstore saved as 'baymax_vectorstore/'\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Build vectorstore\n",
    "vectorstore = FAISS.from_documents(document_chunks, embedding_model)\n",
    "\n",
    "# Save locally\n",
    "vectorstore.save_local(\"baymax_vectorstore\")\n",
    "print(\"✅ Vectorstore saved as 'baymax_vectorstore/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e750216c",
   "metadata": {},
   "source": [
    "## RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2c7769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vectorstore loaded.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Load the same embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load vectorstore from disk\n",
    "vectorstore = FAISS.load_local(\"baymax_vectorstore\", embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "print(\"✅ Vectorstore loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97ba7805",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"A patient has fever for 7 days with back pain. What could be the causes?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f99a02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Match 1 ---\n",
      "Infectious\n",
      "(1) Bacterial\n",
      "(a) Bacterial endocarditis\n",
      "(b) Lyme disease\n",
      "(2) Viral\n",
      "(a) Rubella\n",
      "(b) Hepatitis B\n",
      "(c) HIV\n",
      "(d) Parvovirus\n",
      "(3) Postinfectious\n",
      "(a) Enteric\n",
      "(b) Urogenital\n",
      "(c) Rheumatic fever\n",
      "2. Noninflammatory: OA\n",
      "1\n",
      "Mrs. K’s symptoms started after she stepped down from\n",
      "a bus with unusual force. The pain became intolerable\n",
      "within about 6 hours of onset and has been present for\n",
      "3 days now. She otherwise feels well. She reports no\n",
      "fevers, chills, dietary changes, or sick contacts. On physical \n",
      "Source: symptom_flow\n",
      "\n",
      "--- Match 2 ---\n",
      "He cancels a follow\n",
      "up appointment 1 month later, leaving a message\n",
      "that his pain is gone and he has resumed all of his\n",
      "usual activities. CHIEF COMPLAINT\n",
      "PATIENT 2\n",
      "Mrs. H, a 47-year-old woman, was well until 2 days ago, when\n",
      "she developed low back pain after working in her garden and\n",
      "pulling weeds for several hours. The pain is a constant, dull\n",
      "ache that radiates to her right buttock and hip. Yesterday,\n",
      "after sitting in a movie, the pain began radiating to the back\n",
      "of the right knee. She has tak\n",
      "Source: symptom_flow\n",
      "\n",
      "--- Match 3 ---\n",
      "After attending physical therapy for\n",
      "8 weeks, he reports some improvement in his exercise tol-\n",
      "erance, although he still has daily pain. An epidural corti-\n",
      "costeroid injection provides more pain relief, and he is\n",
      "able to continue a walking program. REVIEW OF OTHER IMPORTANT DISEASES\n",
      "Spinal Epidural Abscess\n",
      "Textbook Presentation\n",
      "The classic presentation is a patient with a history of diabetes or\n",
      "injection drug use who has fever and back pain, followed by neu-\n",
      "rologic symptoms (eg, motor weakness,\n",
      "Source: symptom_flow\n",
      "\n",
      "--- Match 4 ---\n",
      "Fever \n",
      "disappears for a few days \n",
      "only to come back again. This may go on for months \n",
      "or years. Childbirth fever: (see p. 276)\n",
      "Begins a day or more after \n",
      "giving birth. Starts with a slight \n",
      "fever, which often rises later. Foul-smelling vaginal discharge. Pain and sometimes bleeding. All of these illnesses can be dangerous. In addition to those shown here, there \n",
      "are many other diseases that may cause similar signs and fever. For example, fevers \n",
      "that last for more than 1 month, or night sweats,\n",
      "Source: rural_care\n",
      "\n",
      "--- Match 5 ---\n",
      "Then, fever may \n",
      "come for a few hours every second \n",
      "or third day. On other days, the \n",
      "person may feel more or less well. Typhoid: (see p. 188)\n",
      "Begins like a cold. Temperature \n",
      "goes up a little more each day. Pulse relatively slow. Sometimes \n",
      "diarrhea and dehydration. Trembling or delirium (mind \n",
      "wanders). Person very ill.\n",
      "Typhus: (see p. 190)\n",
      "Similar to typhoid. Rash similar to \n",
      "that of measles, with tiny bruises. Hepatitis: (see p. 172)\n",
      "Person loses appetite. Does not \n",
      "wish to eat or smoke. Wan\n",
      "Source: rural_care\n"
     ]
    }
   ],
   "source": [
    "docs = vectorstore.similarity_search(query, k=5)\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\n--- Match {i+1} ---\")\n",
    "    print(doc.page_content[:500])\n",
    "    print(f\"Source: {doc.metadata['source']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61f03f5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ChatGroq' from 'langchain.chat_models' (/Users/devayushrout/Desktop/Baymax/venv/lib/python3.9/site-packages/langchain/chat_models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGroq\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetrievalQA\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ChatGroq' from 'langchain.chat_models' (/Users/devayushrout/Desktop/Baymax/venv/lib/python3.9/site-packages/langchain/chat_models/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"your-groq-key-here\"  # Or set it in env\n",
    "\n",
    "llm = ChatGroq(\n",
    "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
    "    model_name=\"llama3-70b-8192\",\n",
    "    temperature=0.0  # Less hallucination\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb6c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
