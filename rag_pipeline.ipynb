{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "005de078",
   "metadata": {},
   "source": [
    "## Another Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0488205e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/devayushrout/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "153f74f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYMPTOM_KEYWORDS = [\n",
    "    \"fever\", \"cough\", \"cold\", \"pain\", \"headache\", \"vomiting\", \"diarrhea\",\n",
    "    \"sore throat\", \"rash\", \"swelling\", \"chills\", \"fatigue\", \"nausea\",\n",
    "    \"shortness of breath\", \"wheezing\", \"bleeding\", \"dizziness\", \"burns\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b34b170e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done. Total chunks created: 4599\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "SYMPTOM_KEYWORDS = [\n",
    "    \"fever\", \"cough\", \"cold\", \"pain\", \"headache\", \"vomiting\", \"diarrhea\",\n",
    "    \"sore throat\", \"rash\", \"swelling\", \"chills\", \"fatigue\", \"nausea\",\n",
    "    \"shortness of breath\", \"wheezing\", \"bleeding\", \"dizziness\", \"burns\",\n",
    "]\n",
    "\n",
    "def find_symptoms(sentence):\n",
    "    symptoms = [s for s in SYMPTOM_KEYWORDS if s.lower() in sentence.lower()]\n",
    "    return symptoms\n",
    "\n",
    "def smart_chunk_text(text, source_name, priority=1, chunk_size=4):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(sentences):\n",
    "        group = sentences[i:i+chunk_size]\n",
    "        combined = \" \".join(group)\n",
    "        found = []\n",
    "\n",
    "        for sent in group:\n",
    "            found += find_symptoms(sent)\n",
    "\n",
    "        found = list(set(found))  # Remove duplicates\n",
    "\n",
    "        if found:\n",
    "            chunk = {\n",
    "                \"text\": combined,\n",
    "                \"symptoms\": found,\n",
    "                \"source\": source_name,\n",
    "                \"type\": \"rural_remedy\" if \"no_doctor\" in source_name else \"clinical\",\n",
    "                \"priority\": priority\n",
    "            }\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        i += chunk_size\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# 🔄 Loop over all text files in your knowledge base\n",
    "all_chunks = []\n",
    "\n",
    "root_folder = \"Baymax_KnowledgeBase\"  # ← your base folder with 5 sources\n",
    "\n",
    "for folder in os.listdir(root_folder):\n",
    "    folder_path = os.path.join(root_folder, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        priority = 1 if \"no_doctor\" in folder else 2 if \"iphs\" in folder else 3\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".txt\"):\n",
    "                with open(os.path.join(folder_path, file), \"r\", encoding=\"utf-8\") as f:\n",
    "                    text = f.read()\n",
    "                    chunks = smart_chunk_text(text, folder, priority)\n",
    "                    all_chunks.extend(chunks)\n",
    "\n",
    "# 💾 Save all chunks as a JSONL file\n",
    "with open(\"symptom_chunks.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for chunk in all_chunks:\n",
    "        f.write(json.dumps(chunk) + \"\\n\")\n",
    "\n",
    "print(f\"✅ Done. Total chunks created: {len(all_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c408c338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4599 chunks.\n",
      "✅ FAISS vectorstore saved to 'baymax_vectorstore/'\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "\n",
    "# Load your symptom-tagged chunks\n",
    "chunks = []\n",
    "with open(\"symptom_chunks.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        chunks.append(\n",
    "            Document(\n",
    "                page_content=data[\"text\"],\n",
    "                metadata={\n",
    "                    \"symptoms\": data[\"symptoms\"],\n",
    "                    \"source\": data[\"source\"],\n",
    "                    \"type\": data[\"type\"],\n",
    "                    \"priority\": data[\"priority\"]\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"Loaded {len(chunks)} chunks.\")\n",
    "\n",
    "# Set up embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Build FAISS vectorstore from chunks\n",
    "vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
    "\n",
    "# Save it to disk\n",
    "vectorstore.save_local(\"baymax_vectorstore\")\n",
    "print(\"✅ FAISS vectorstore saved to 'baymax_vectorstore/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3226c792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "Text: Where There Is No Doctor 2011\n",
      "162\n",
      "HEADACHES AND MIGRAINES\n",
      "SIMPLE HEADACHE can be helped by rest \n",
      "and aspirin. It often helps to put a cloth \n",
      "soaked in hot water on the back of the \n",
      "neck and to massage (rub) the neck \n",
      "and shoulders gently. Some other home \n",
      "remedies also seem to help. Headache is comm\n",
      "Metadata: {'symptoms': ['fever', 'headache'], 'source': 'rural_care', 'type': 'clinical', 'priority': 3}\n",
      "\n",
      "---\n",
      "Text: Let \n",
      "the air reach his body. This will help the fever go \n",
      "down (see p. 76). True. It helps.\n",
      "Metadata: {'symptoms': ['fever'], 'source': 'rural_care', 'type': 'clinical', 'priority': 3}\n",
      "\n",
      "---\n",
      "Text: 4. \u0007Pour cool (not cold) water over him, or put cloths soaked in cool water on his \n",
      "chest and forehead. Fan the cloths and change them often to keep them cool. Continue to do this until the fever goes down (below 38°).\n",
      "Metadata: {'symptoms': ['cold', 'fever'], 'source': 'rural_care', 'type': 'clinical', 'priority': 3}\n",
      "\n",
      "---\n",
      "Text: Bring the fever down as soon \n",
      "as you can and treat the cause of the fever, if possible. High fever can cause seizures \n",
      "(convulsions) and is most dangerous for small children. When a fever goes very high (over 40°), it must be lowered at once:\n",
      "1. Put the person in a cool place.\n",
      "Metadata: {'symptoms': ['fever'], 'source': 'rural_care', 'type': 'clinical', 'priority': 3}\n",
      "\n",
      "---\n",
      "Text: Ask a health worker which medicine works best where \n",
      "you live. ♦\t Lower the fever with cool wet cloths (see p. 76). ♦\t Give plenty of liquids: soups, juices, and Rehydration Drink to avoid dehydration \n",
      "(see p. 152). ♦\t Give nutritious foods, in liquid form if necessary.\n",
      "Metadata: {'symptoms': ['fever'], 'source': 'rural_care', 'type': 'clinical', 'priority': 3}\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Load saved vectorstore\n",
    "vs = FAISS.load_local(\"baymax_vectorstore\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Test a query\n",
    "docs = vs.similarity_search(\"What to do if someone has fever and headache?\", k=5)\n",
    "\n",
    "for doc in docs:\n",
    "    print(\"\\n---\")\n",
    "    print(\"Text:\", doc.page_content[:300])\n",
    "    print(\"Metadata:\", doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8408165a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
